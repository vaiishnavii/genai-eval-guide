# References

- Bai, X., Wei, J., Du, Y., et al. (2023). *Constitutional AI: Harmlessness from AI feedback*. Anthropic. Retrieved from https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback
  
- Google Developers. (n.d.). *Fairness: Evaluating for Bias*. Retrieved April 22, 2025, from https://developers.google.com/machine-learning/fairness-overview

- IBM Research. (2023). *What is Red Teaming for Generative AI?* IBM. Retrieved from https://research.ibm.com/blog/what-is-red-teaming-gen-AI

- OpenAI. (2023). *GPT-4 System Card* https://cdn.openai.com/papers/gpt-4-system-card.pdf

- Stanford Center for Research on Foundation Models. (2023). *HELM: Holistic Evaluation of Language Models*. Retrieved from https://crfm.stanford.edu/helm/latest/

- West, J., & Bergstrom, C. (2025). *Modern Day Oracles or Bullshit Machines?* The Bullshit Machines. Retrieved from https://thebullshitmachines.com

- Mollick, E. (2024). *15 Times to Use AI, and 5 Not To*. One Useful Thing. Retrieved from https://www.oneusefulthing.org

- Resnick, M. (2024). *Generative AI and Creative Learning: Concerns, Opportunities, and Choices*. From Novel Chemicals to Opera https://mit-genai.pubpub.org/pub/gj6eod3e/release/2
